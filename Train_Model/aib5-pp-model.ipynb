{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraly","metadata":{}},{"cell_type":"code","source":"import timm\nimport torch.nn.functional as F\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\nfrom torchvision.datasets import ImageFolder\nimport numpy as np\nimport seaborn as sns\nimport shutil\nimport matplotlib.pyplot as plt\nimport os \nimport gdown\nfrom tqdm import tqdm\nimport copy\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\nfrom sklearn.metrics import f1_score, confusion_matrix, accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:14:20.843765Z","iopub.execute_input":"2025-05-27T15:14:20.844477Z","iopub.status.idle":"2025-05-27T15:14:30.056519Z","shell.execute_reply.started":"2025-05-27T15:14:20.844452Z","shell.execute_reply":"2025-05-27T15:14:30.055903Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"url1 = \"https://drive.google.com/file/d/19u7gzEMboCQHjU6umzsrym5ax9O2JvhM/view?usp=sharing\"\noutput1 = \"/kaggle/working/dataset.zip\"\ngdown.download(url=url1, output=output1, fuzzy=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:14:30.057788Z","iopub.execute_input":"2025-05-27T15:14:30.058284Z","iopub.status.idle":"2025-05-27T15:14:55.633467Z","shell.execute_reply.started":"2025-05-27T15:14:30.058258Z","shell.execute_reply":"2025-05-27T15:14:55.632888Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from zipfile import ZipFile\n  \nwith ZipFile(\"/kaggle/working/dataset.zip\", 'r') as zObject:\n      zObject.extractall(\n        path='./')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:14:55.634280Z","iopub.execute_input":"2025-05-27T15:14:55.634567Z","iopub.status.idle":"2025-05-27T15:15:00.583563Z","shell.execute_reply.started":"2025-05-27T15:14:55.634549Z","shell.execute_reply":"2025-05-27T15:15:00.582694Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data preprocessing","metadata":{}},{"cell_type":"code","source":"mean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ntrain_transform = transforms.Compose([\n    transforms.Resize((448, 448)), \n    transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), shear=15),\n    transforms.RandomPerspective(distortion_scale=0.3, p=0.3),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n    transforms.GaussianBlur(kernel_size=(5, 5), sigma=(0.1, 2.0)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std)\n])\n\n# Transform สำหรับ validation\nval_transform = transforms.Compose([\n    transforms.Resize((448, 448)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std)\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((448, 448)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std)\n])\n\ntrain_dir = '/kaggle/working/datasets_and_pseudo_data/Train'\nval_dir = '/kaggle/working/datasets_and_pseudo_data/Validation'\ntest_dir = '/kaggle/working/datasets_and_pseudo_data/Test'\n\ntrain_dataset = ImageFolder(root=train_dir, transform=train_transform)\nval_dataset = ImageFolder(root=val_dir, transform=val_transform)\ntest_dataset = ImageFolder(root=test_dir, transform=test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:15:00.585085Z","iopub.execute_input":"2025-05-27T15:15:00.585310Z","iopub.status.idle":"2025-05-27T15:15:00.617724Z","shell.execute_reply.started":"2025-05-27T15:15:00.585294Z","shell.execute_reply":"2025-05-27T15:15:00.616879Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from collections import Counter\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef count_images_per_class(dataset, dataset_name):\n    class_names = dataset.classes\n    class_counts = Counter(dataset.targets)\n    counts = {class_names[idx]: count for idx, count in class_counts.items()}\n    \n    print(f\"\\n{dataset_name} Class Distribution:\")\n    for class_name, count in counts.items():\n        print(f\"Class {class_name}: {count} images\")\n    \n    return counts, class_names\n\ntrain_counts, train_class_names = count_images_per_class(train_dataset, \"Train\")\nval_counts, val_class_names = count_images_per_class(val_dataset, \"Validation\")\ntest_counts, test_class_names = count_images_per_class(test_dataset, \"Test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:15:00.618541Z","iopub.execute_input":"2025-05-27T15:15:00.619274Z","iopub.status.idle":"2025-05-27T15:15:00.627887Z","shell.execute_reply.started":"2025-05-27T15:15:00.619245Z","shell.execute_reply":"2025-05-27T15:15:00.627088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot class\ndef plot_class_distribution(counts, class_names, dataset_name):\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x=list(counts.keys()), y=list(counts.values()))\n    plt.xticks(rotation=45)\n    plt.xlabel('Class')\n    plt.ylabel('Number of Images')\n    plt.title(f'{dataset_name} Class Distribution')\n    plt.tight_layout()\n    plt.savefig(f'/kaggle/working/{dataset_name.lower()}_class_distribution.png')\n    plt.show()\n\nplot_class_distribution(train_counts, train_class_names, \"Train\")\nplot_class_distribution(val_counts, val_class_names, \"Validation\")\nplot_class_distribution(test_counts, test_class_names, \"Test\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:15:00.628891Z","iopub.execute_input":"2025-05-27T15:15:00.629141Z","iopub.status.idle":"2025-05-27T15:15:01.647506Z","shell.execute_reply.started":"2025-05-27T15:15:00.629097Z","shell.execute_reply":"2025-05-27T15:15:01.646884Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchvision\ndef denormalize(tensor, mean, std):\n    for t, m, s in zip(tensor, mean, std):\n        t.mul_(s).add_(m) \n    return tensor\ndata_iter = iter(train_loader)\nimages, labels = next(data_iter)\ndenorm_images = torch.stack([denormalize(img.clone(), mean, std) for img in images])\n\n# แปลงเป็น Grid และแสดงผล\nimg_grid = torchvision.utils.make_grid(denorm_images, nrow=8, padding=2, normalize=False)\nplt.figure(figsize=(12, 6))\nplt.imshow(np.transpose(img_grid.numpy(), (1, 2, 0))) \nplt.axis('off')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:15:01.648342Z","iopub.execute_input":"2025-05-27T15:15:01.648912Z","iopub.status.idle":"2025-05-27T15:15:08.993957Z","shell.execute_reply.started":"2025-05-27T15:15:01.648885Z","shell.execute_reply":"2025-05-27T15:15:08.992825Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CNN_MODEL","metadata":{}},{"cell_type":"code","source":"class SEBlock(nn.Module):\n    def __init__(self, channels, reduction=16):\n        super(SEBlock, self).__init__()\n        self.fc = nn.Sequential(\n            nn.Linear(channels, channels // reduction),\n            nn.ReLU(),\n            nn.Linear(channels // reduction, channels),\n            nn.Sigmoid()\n        )\n    \n    def forward(self, x):\n        b, seq_len, c = x.size()\n        y = x.mean(dim=1) \n        y = self.fc(y)    \n        return x * y.unsqueeze(1).expand_as(x)\n\n# Cross-Stage Attention\nclass CrossStageAttention(nn.Module):\n    def __init__(self, channels, num_heads=4):\n        super().__init__()\n        self.num_heads = num_heads\n        self.qkv = nn.Linear(channels, channels * 3)\n        self.proj = nn.Linear(channels, 64)\n        self.scale = (channels // num_heads) ** -0.5\n    \n    def forward(self, x_list):\n        B = x_list[0].shape[0]\n        x = torch.cat(x_list, dim=1)  \n        qkv = self.qkv(x).chunk(3, dim=-1)\n        q, k, v = map(lambda t: t.reshape(B, -1, self.num_heads, t.shape[-1]//self.num_heads).permute(0, 2, 1, 3), qkv)\n        attn = (q @ k.transpose(-2, -1)) * self.scale\n        attn = attn.softmax(dim=-1)\n        x = (attn @ v).transpose(1, 2).reshape(B, -1, x.shape[-1])\n        \n        return self.proj(x.mean(dim=1))\n\n# Dynamic Feature Reducer\nclass DynamicFeatureReducer(nn.Module):\n    def __init__(self, in_channels):\n        super().__init__()\n        self.proj = nn.Linear(in_channels, 128)\n        self.se = SEBlock(128)\n        self.norm = nn.LayerNorm(128)\n    \n    def forward(self, x):\n        x = self.proj(x)     \n        x = self.norm(x)\n        x = self.se(x)\n        return x\n\n# Main Model \nclass vit_base_patch32_model(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        \n        self.backbone = timm.create_model(\n            'vit_base_patch32_clip_448.laion2b_ft_in12k_in1k', \n            pretrained=True,\n            num_classes=0  \n        )\n                if hasattr(self.backbone, 'set_grad_checkpointing'):\n            self.backbone.set_grad_checkpointing(True)\n        \n\n        for name, param in self.backbone.named_parameters():\n            if any(layer in name for layer in ['blocks.10', 'blocks.11', 'norm', 'head']):\n                param.requires_grad = True\n            else:\n                param.requires_grad = False\n        \n        self.hidden_dim = 768\n        self.feature_layers = [9, 11]\n        self.reducers = nn.ModuleList([\n            DynamicFeatureReducer(self.hidden_dim) for _ in self.feature_layers\n        ])\n        \n        self.cross_attention = CrossStageAttention(channels=128)\n        self.classifier = nn.Sequential(\n            nn.Linear(64, 128),\n            nn.GELU(),\n            nn.Dropout(0.1),\n            nn.Linear(128, num_classes)\n        )\n        \n        self.temperature = nn.Parameter(torch.ones(1))\n    \n    def forward_features(self, x):\n        x = self.backbone.patch_embed(x)\n        x = self.backbone._pos_embed(x)\n        x = self.backbone.patch_drop(x)\n        x = self.backbone.norm_pre(x)\n        \n        intermediate_features = {}\n    \n        for i, block in enumerate(self.backbone.blocks):\n            x = block(x)\n            if i in self.feature_layers:\n                intermediate_features[i] = x\n        \n        return intermediate_features\n    \n    def forward(self, x, return_features=False):\n        intermediate_features = self.forward_features(x)\n        \n        reduced_features = []\n        for i, layer_idx in enumerate(self.feature_layers):\n            feat = intermediate_features[layer_idx]\n            reduced = self.reducers[i](feat)\n            reduced_features.append(reduced)\n        \n        x = self.cross_attention(reduced_features)\n        \n        features = self.classifier[:3](x)  \n        logits = self.classifier[3:](features)  \n        logits = logits / self.temperature\n        \n        if return_features:\n            return features\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:15:08.995390Z","iopub.execute_input":"2025-05-27T15:15:08.995699Z","iopub.status.idle":"2025-05-27T15:15:09.022411Z","shell.execute_reply.started":"2025-05-27T15:15:08.995663Z","shell.execute_reply":"2025-05-27T15:15:09.021276Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loss Function","metadata":{}},{"cell_type":"code","source":"class LabelSmoothedCrossEntropy(nn.Module):\n    def __init__(self, smoothing=0.1, reduction='mean'):\n        super().__init__()\n        self.smoothing = smoothing\n        self.reduction = reduction\n\n    def forward(self, logits, target):\n        log_probs = logits.log_softmax(dim=-1)\n        nll = -log_probs.gather(dim=-1, index=target.unsqueeze(1)).squeeze(1)\n        smooth_loss = -log_probs.mean(dim=-1)\n        loss = (1.0 - self.smoothing) * nll + self.smoothing * smooth_loss\n        \n        if self.reduction == 'mean':\n            return loss.mean()\n        elif self.reduction == 'sum':\n            return loss.sum()\n        else:\n            return loss\n\nclass FocalLoss(nn.Module):\n    def __init__(self, gamma=2, reduction='mean'):\n        super().__init__()\n        self.gamma = gamma\n        self.reduction = reduction\n\n    def forward(self, inputs, targets):\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n        pt = torch.exp(-ce_loss)\n        focal_loss = ((1 - pt) ** self.gamma * ce_loss)\n        \n        if self.reduction == 'mean':\n            return focal_loss.mean()\n        elif self.reduction == 'sum':\n            return focal_loss.sum()\n        else:\n            return focal_loss\n\ndef combined_loss(logits, targets):\n    ls = LabelSmoothedCrossEntropy(smoothing=0.1, reduction='mean')(logits, targets)\n    fl = FocalLoss(gamma=2, reduction='mean')(logits, targets)\n    return 0.7 * ls + 0.3 * fl","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:15:09.023437Z","iopub.execute_input":"2025-05-27T15:15:09.023729Z","iopub.status.idle":"2025-05-27T15:15:09.036430Z","shell.execute_reply.started":"2025-05-27T15:15:09.023709Z","shell.execute_reply":"2025-05-27T15:15:09.035546Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#  Train","metadata":{}},{"cell_type":"code","source":"from torch.amp import GradScaler, autocast\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n\n# Early Stopping\nclass EarlyStopping:\n    def __init__(self, patience=5, delta=0, path='checkpoint.pt', verbose=True, monitor='val_loss'):\n        self.patience = patience\n        self.delta = delta\n        self.path = path\n        self.verbose = verbose\n        self.counter = 0\n        self.best_score = None\n        self.early_stop = False\n        self.monitor = monitor\n        \n        if self.monitor == 'val_loss':\n            self.val_score_min = float('inf')\n            self.improvement_check = lambda score, best: score < best - self.delta\n        else:  # 'val_acc'\n            self.val_score_min = -float('inf')\n            self.improvement_check = lambda score, best: score > best + self.delta\n            \n    def __call__(self, val_score, model):\n        score = -val_score if self.monitor == 'val_loss' else val_score\n        \n        if self.best_score is None:\n            self.best_score = score\n            self.save_checkpoint(val_score, model)\n        elif not self.improvement_check(score, self.best_score):\n            self.counter += 1\n            if self.verbose:\n                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n            if self.counter >= self.patience:\n                self.early_stop = True\n        else:\n            self.best_score = score\n            self.save_checkpoint(val_score, model)\n            self.counter = 0\n            \n    def save_checkpoint(self, val_score, model):\n        if self.verbose:\n            score_label = \"loss\" if self.monitor == \"val_loss\" else \"accuracy\"\n            print(f'Validation {score_label} improved ({self.val_score_min:.6f} --> {val_score:.6f}). Saving model...')\n        torch.save(model.state_dict(), self.path)\n        self.val_score_min = val_score\n\n# Validation Function\ndef validate(model, val_loader, device, criterion=None):\n    if criterion is None:\n        criterion = nn.CrossEntropyLoss()\n        \n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    \n    val_pbar = tqdm(val_loader, desc=\"Validation\")\n    \n    with torch.no_grad():\n        for images, labels in val_pbar:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item() * images.size(0)\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n            curr_loss = val_loss / total\n            curr_acc = 100.0 * correct / total\n            val_pbar.set_postfix(loss=f\"{curr_loss:.4f}\", acc=f\"{curr_acc:.2f}%\")\n    \n    return val_loss / total, correct / total\n\ndef train_model(model, train_loader, val_loader, device, \n                num_epochs=50, patience=7, delta=0.001, \n                checkpoint_path='best_model.pth', final_model_path='Cassava_convnext_large.pth',\n                criterion=None):  \n    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n    scaler = GradScaler() \n    \n    if criterion is None:\n        criterion = nn.CrossEntropyLoss()\n    \n    early_stopping = EarlyStopping(patience=patience, delta=delta, path=checkpoint_path, \n                                  verbose=True, monitor='val_acc')\n    history = {\n        'train_loss': [],\n        'train_acc': [],\n        'val_loss': [],\n        'val_acc': []\n    }\n\n    for epoch in range(num_epochs):\n        model.train()\n        running_loss = 0.0\n        correct = 0\n        total = 0\n        \n        train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\")\n        for images, labels in train_pbar:\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n\n            with autocast('cuda'): \n                outputs = model(images)\n                loss = criterion(outputs, labels)  # ใช้ criterion ที่ส่งเข้ามา\n\n            scaler.scale(loss).backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            scaler.step(optimizer)\n            scaler.update()\n\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n            running_loss += loss.item() * images.size(0)\n            total += labels.size(0)\n            \n            # อัพเดท progress bar \n            curr_loss = running_loss / total\n            curr_acc = 100.0 * correct / total\n            train_pbar.set_postfix(loss=f\"{curr_loss:.4f}\", acc=f\"{curr_acc:.2f}%\")\n\n        # คำนวณและบันทึกค่า train loss และ accuracy\n        train_loss = running_loss / total\n        train_acc = correct / total\n        history['train_loss'].append(train_loss)\n        history['train_acc'].append(train_acc)\n        \n        # Validation phase\n        val_loss, val_acc = validate(model, val_loader, device, criterion)  \n        history['val_loss'].append(val_loss)\n        history['val_acc'].append(val_acc)\n\n        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n\n        # ใช้ Early Stopping\n        early_stopping(val_acc, model)\n        \n        if early_stopping.early_stop:\n            print(f\"Early stopping triggered at epoch {epoch+1}\")\n            break\n\n        scheduler.step()\n    \n    # โหลดโมเดลที่ดีที่สุด\n    model.load_state_dict(torch.load(checkpoint_path))\n    \n    # บันทึกโมเดลสุดท้าย\n    torch.save(model.state_dict(), final_model_path)\n    print(f\"Final model saved to {final_model_path}\")\n    \n    actual_epochs = len(history['val_loss'])\n    \n    return model, history, actual_epochs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:15:09.040365Z","iopub.execute_input":"2025-05-27T15:15:09.040716Z","iopub.status.idle":"2025-05-27T15:15:09.063940Z","shell.execute_reply.started":"2025-05-27T15:15:09.040694Z","shell.execute_reply":"2025-05-27T15:15:09.063162Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_training_history(history, actual_epochs):\n    epochs = range(1, actual_epochs + 1)\n\n    plt.figure(figsize=(12, 5))\n    \n    # Plot loss\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, history['train_loss'], 'b-', label='Training Loss')\n    plt.plot(epochs, history['val_loss'], 'r-', label='Validation Loss')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n    \n    # Plot accuracy\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, history['train_acc'], 'b-', label='Training Accuracy')\n    plt.plot(epochs, history['val_acc'], 'r-', label='Validation Accuracy')\n    plt.title('Training and Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.grid(True)\n    \n    plt.tight_layout()\n    plt.savefig('training_history.png')\n    plt.show()\n    plt.close()\n    print(f\"Training history graph saved as 'training_history.png' (trained for {actual_epochs} epochs)\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:15:09.064585Z","iopub.execute_input":"2025-05-27T15:15:09.064799Z","iopub.status.idle":"2025-05-27T15:15:09.074974Z","shell.execute_reply.started":"2025-05-27T15:15:09.064776Z","shell.execute_reply":"2025-05-27T15:15:09.074233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nnum_classes = 5\nmodel = vit_base_patch32_model(num_classes=num_classes).to(device)\ncriterion = combined_loss\n\nif torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs!\")\n    model = nn.DataParallel(model, device_ids=[0, 1])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:15:09.075856Z","iopub.execute_input":"2025-05-27T15:15:09.076091Z","iopub.status.idle":"2025-05-27T15:15:12.602054Z","shell.execute_reply.started":"2025-05-27T15:15:09.076071Z","shell.execute_reply":"2025-05-27T15:15:12.601272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model, history, actual_epochs = train_model(\n    model, \n    train_loader, \n    val_loader, \n    device,\n    criterion=criterion,\n    num_epochs=100, \n    patience=5, \n    delta=0.001,\n    checkpoint_path='best_model.pth', \n    final_model_path='vit_base_patch32.pth'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:15:12.602955Z","iopub.execute_input":"2025-05-27T15:15:12.603262Z","iopub.status.idle":"2025-05-27T15:39:08.981015Z","shell.execute_reply.started":"2025-05-27T15:15:12.603238Z","shell.execute_reply":"2025-05-27T15:39:08.980245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model_state_dict.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:39:08.982222Z","iopub.execute_input":"2025-05-27T15:39:08.982483Z","iopub.status.idle":"2025-05-27T15:39:09.401138Z","shell.execute_reply.started":"2025-05-27T15:39:08.982460Z","shell.execute_reply":"2025-05-27T15:39:09.400355Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Plot_Grap_Training","metadata":{}},{"cell_type":"code","source":"plot_training_history(history, actual_epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:39:09.402105Z","iopub.execute_input":"2025-05-27T15:39:09.402342Z","iopub.status.idle":"2025-05-27T15:39:09.940207Z","shell.execute_reply.started":"2025-05-27T15:39:09.402323Z","shell.execute_reply":"2025-05-27T15:39:09.939545Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# EVALUATE Confusion Metric and F1 Score","metadata":{}},{"cell_type":"code","source":"def final_evaluate(model, test_loader, device):\n    model.eval()\n    y_true = []\n    y_pred = []\n    \n    test_pbar = tqdm(test_loader, desc=\"Testing\")\n    with torch.no_grad():\n        for images, labels in test_pbar:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            y_true.extend(labels.cpu().numpy())\n            y_pred.extend(preds.cpu().numpy())\n    acc = accuracy_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred, average='macro')\n    cm = confusion_matrix(y_true, y_pred)\n    print(f\"Test Accuracy: {acc:.4f}\")\n    print(f\"Test F1 Score: {f1:.4f}\")\n    print(\"Classification Report:\")\n    print(classification_report(y_true, y_pred, digits=4))\n    # Confusion Matrix\n    class_names = ['CBB', 'CBSD', 'CGM', 'CMD', 'Healthy']\n    plt.figure(figsize=(10, 8))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n    plt.xlabel('Predicted')\n    plt.ylabel('True')\n    plt.title('Confusion Matrix')\n    plt.savefig('confusion_matrix.png')\n    plt.show()\n    plt.close()\n    print(\"Confusion matrix saved as 'confusion_matrix.png'\")\n    all_preds = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            \n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    print(\"\\nError Analysis per Class:\")\n    for i, class_name in enumerate(class_names):\n        true_count = sum(1 for label in all_labels if label == i)\n        correct_count = sum(1 for true, pred in zip(all_labels, all_preds) if true == i and pred == i)\n        \n        if true_count > 0:\n            accuracy = correct_count / true_count * 100\n            error_rate = 100 - accuracy\n            print(f\"{class_name}: {correct_count}/{true_count} correct ({accuracy:.1f}% accuracy, {error_rate:.1f}% error)\")\n\n\n    return acc, f1, cm\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:39:09.941035Z","iopub.execute_input":"2025-05-27T15:39:09.941293Z","iopub.status.idle":"2025-05-27T15:39:09.951900Z","shell.execute_reply.started":"2025-05-27T15:39:09.941266Z","shell.execute_reply":"2025-05-27T15:39:09.951098Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_acc, test_f1, test_cm = final_evaluate(model, test_loader, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:39:09.952590Z","iopub.execute_input":"2025-05-27T15:39:09.952908Z","iopub.status.idle":"2025-05-27T15:39:34.223043Z","shell.execute_reply.started":"2025-05-27T15:39:09.952886Z","shell.execute_reply":"2025-05-27T15:39:34.222099Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"เปรียบเทียบกับ https://www.kaggle.com/code/pradiptadatta/cassava-leaf-disease-best-quality\n                                     precision    recall  f1-score   support\n\n     Cassava Bacterial Blight (CBB)       0.71      0.65      0.68       311\n     Cassava Brown Streak Disease (CBSD)  0.86      0.82      0.84       726\n     Cassava Green Mottle (CGM)           0.83      0.79      0.81       632\n     Cassava Mosaic Disease (CMD)         0.95      0.97      0.96      3163\n                            Healthy       0.76      0.78      0.77       579\n\n                           accuracy                           0.89      5411\n                          macro avg       0.82      0.80      0.81      5411\n                       weighted avg       0.89      0.89      0.89      5411","metadata":{}},{"cell_type":"markdown","source":"# Error Analysis","metadata":{}},{"cell_type":"code","source":"import os\nfrom collections import defaultdict\n\ndef show_misclassified_by_class(model, test_loader, device, class_names, max_per_class=12, save_dir=\"misclassified_by_class\"):\n    \n    misclassified_by_class = defaultdict(lambda: {\n        'images': [],\n        'true_labels': [],\n        'pred_labels': []\n    })\n    \n    os.makedirs(save_dir, exist_ok=True)\n    \n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            _, preds = torch.max(outputs, 1)\n            \n            # หาตัวที่ผิด\n            wrong_indices = (preds != labels).nonzero(as_tuple=True)[0]\n            \n            for idx in wrong_indices:\n                true_class = labels[idx].item()\n                pred_class = preds[idx].item()\n                \n                # เก็บข้อมูลตามคลาสจริง\n                if len(misclassified_by_class[true_class]['images']) < max_per_class:\n                    misclassified_by_class[true_class]['images'].append(images[idx].cpu())\n                    misclassified_by_class[true_class]['true_labels'].append(true_class)\n                    misclassified_by_class[true_class]['pred_labels'].append(pred_class)\n    \n    for class_idx, data in misclassified_by_class.items():\n        if len(data['images']) == 0:\n            continue\n            \n        class_name = class_names[class_idx]\n        n_images = len(data['images'])\n        \n        cols = min(3, n_images)\n        rows = (n_images + cols - 1) // cols\n        \n        plt.figure(figsize=(12, 4 * rows))\n        plt.suptitle(f'True Class: {class_name}', fontsize=16, fontweight='bold')\n        \n        for i in range(n_images):\n            image = data['images'][i]\n            true_label = class_names[data['true_labels'][i]]\n            pred_label = class_names[data['pred_labels'][i]]\n            \n            img_np = image.permute(1, 2, 0).numpy()\n            mean = np.array([0.485, 0.456, 0.406])\n            std = np.array([0.229, 0.224, 0.225])\n            img_np = img_np * std + mean\n            img_np = np.clip(img_np, 0, 1)  \n            \n            plt.subplot(rows, cols, i + 1)\n            plt.imshow(img_np)\n            plt.title(f\"Predicted: {pred_label}\", fontsize=12, color='red')\n            plt.axis('off')\n            \n            save_path = os.path.join(save_dir, f\"{class_name}_img_{i+1}_pred_{pred_label}.png\")\n            plt.imsave(save_path, img_np)\n        \n        plt.tight_layout()\n        plt.show()\n        \n        print(f\"Class '{class_name}': Found {n_images} misclassified images\")\n        \n        pred_counts = defaultdict(int)\n        for pred_idx in data['pred_labels']:\n            pred_counts[class_names[pred_idx]] += 1\n        \n        print(f\"  Most confused with:\")\n        for pred_class, count in sorted(pred_counts.items(), key=lambda x: x[1], reverse=True):\n            print(f\"    - {pred_class}: {count} times\")\n        print(\"-\" * 50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:39:34.224157Z","iopub.execute_input":"2025-05-27T15:39:34.224462Z","iopub.status.idle":"2025-05-27T15:39:34.236793Z","shell.execute_reply.started":"2025-05-27T15:39:34.224435Z","shell.execute_reply":"2025-05-27T15:39:34.236084Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = ['CBB', 'CBSD', 'CGM', 'CMD', 'Healthy']\nshow_misclassified_by_class(model, test_loader, device, class_names, max_per_class=12)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-27T15:39:34.237480Z","iopub.execute_input":"2025-05-27T15:39:34.237735Z","iopub.status.idle":"2025-05-27T15:40:02.527712Z","shell.execute_reply.started":"2025-05-27T15:39:34.237718Z","shell.execute_reply":"2025-05-27T15:40:02.526565Z"}},"outputs":[],"execution_count":null}]}